<?xml version="1.0"?>
<!-- NOTE:  This file is managed by Puppet. -->

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <!-- Hive Configuration can either be stored in this file or in the hadoop configuration files  -->
  <!-- that are implied by Hadoop setup variables.                                                -->
  <!-- Aside from Hadoop setup variables - this file is provided as a convenience so that Hive    -->
  <!-- users do not have to edit hadoop configuration files (that may be managed as a centralized -->
  <!-- resource).                                                                                 -->

  <!-- Hive metastore configuration -->
  <property>
    <name>hive.metastore.local</name>
    <value>true</value>
    <description>This property was obsoleted in Hive 0.10, but Hue/Beeswax requires it to connect correctly.</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/hive_metastore</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>
  
    <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
  </property>
  
  <property>
    <name>datanucleus.autoCreateSchema</name>
    <value>false</value>
  </property>

  <property>
    <name>datanucleus.fixedDatastore</name>
    <value>true</value>
  </property>


  <!-- Hive can use Zookeeper for table lock management -->
  <property>
    <name>hive.support.concurrency</name>
    <value>true</value>
    <description>Enable Hive's Table Lock Manager Service</description>
  </property>

  <property>
    <name>hive.zookeeper.quorum</name>
    <description>Zookeeper quorum used by Hive's Table Lock Manager</description>
    <value>analytics1023.eqiad.wmnet,analytics1024.eqiad.wmnet,analytics1025.eqiad.wmnet</value>
  </property>
  
  <property>
    <name>hive.multi.insert.move.tasks.share.dependencies</name>
    <value>false</value>
    <description>
      If this is set all move tasks for tables/partitions (not directories) at the end of a
      multi-insert query will only begin once the dependencies for all these move tasks have been
      met.
      Advantages: If concurrency is enabled, the locks will only be released once the query has
                  finished, so with this config enabled, the time when the table/partition is
                  generated will be much closer to when the lock on it is released.
      Disadvantages: If concurrency is not enabled, with this disabled, the tables/partitions which
                     are produced by this query and finish earlier will be available for querying
                     much earlier.  Since the locks are only released once the query finishes, this
                     does not apply if concurrency is enabled.
    </description>
  </property>
  
  
  <!-- Hive CLI -->
  <property>
    <name>hive.cli.print.current.db</name>
    <description>Whether to include the current database in the hive prompt.</description>
    <value>true</value>
  </property>

  <property>
    <name>hive.cli.print.header</name>
    <description>Whether to print the names of the columns in query output.</description>
    <value>true</value>
  </property>


  <!-- Hive Execution Parameters -->
  <property>
    <name>hive.mapred.mode</name>
    <value>nonstrict</value>
    <description>
      The mode in which the hive operations are being performed. 
      In strict mode, some risky queries are not allowed to run. They include:
       - Cartesian Product.
       - No partition being picked up for a query.
       - Comparing bigints and strings.
       - Comparing bigints and doubles.
       - Orderby without limit.
    </description>
  </property>

  <property>
    <name>hive.task.progress</name>
    <value>true</value>
  </property>
  
  <property>
    <name>hive.exec.dynamic.partition</name>
    <value>true</value>
    <description>Whether or not to allow dynamic partitions in DML/DDL.</description>
  </property>
  
  <property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
  </property>

  <property>
    <name>hive.error.on.empty.partition</name>
    <value>false</value>
    <description>Whether to throw an excpetion if dynamic partition insert generates empty results.</description>
  </property>

  <property>
    <name>hive.insert.into.external.tables</name>
    <value>false</value>
    <description>https://issues.apache.org/jira/browse/HIVE-2837</description>
  </property>

  <property>
    <name>hive.exec.parallel</name>
    <description>Whether to execute jobs in parallel</description>
    <value>true</value>
  </property>
  
  <property>
    <name>hive.exec.parallel.thread.number</name>
    <value>8</value>
    <description>How many jobs at most can be executed in parallel</description>
  </property>
  
  <property>
    <name>hive.start.cleanup.scratchdir</name>
    <description>To cleanup the hive scratchdir while starting the hive server.</description>
    <value>true</value>
  </property>

  <property>
    <name>hive.optimize.skewjoin</name>
    <value>false</value>
    <description>
      Whether to enable skew join optimization.
      The algorithm is as follows: At runtime, detect the keys with a large skew. Instead of
      processing those keys, store them temporarily in a hdfs directory. In a follow-up map-reduce
      job, process those skewed keys. The same key need not be skewed for all the tables, and so,
      the follow-up map-reduce job (for the skewed keys) would be much faster, since it would be a 
      map-join.
    </description>
  </property>
  
  <property>
    <name>hive.skewjoin.key</name>
    <value>10000</value>
    <description>
      Determine if we get a skew key in join. If we see more
      than the specified number of rows with the same key in join operator,
      we think the key as a skew join key.
    </description>
  </property>

  <property>
    <name>hive.skewjoin.mapjoin.map.tasks</name>
    <value>10000</value>
    <description>
      Determine the number of map task used in the follow up map join job
      for a skew join. It should be used together with hive.skewjoin.mapjoin.min.split
      to perform a fine grained control.
    </description> 
  </property>
  

    <!-- Hive stats configuration -->
  <property>
    <name>hive.stats.dbclass</name>
    <value>jdbc:mysql</value>
    <description>The default database that stores temporary hive statistics.</description>
  </property>

  <property>
    <name>hive.stats.jdbcdriver</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>The JDBC driver for the database that stores temporary hive statistics.</description>
  </property>

  <property>
    <name>hive.stats.dbconnectionstring</name>
    <value>jdbc:mysql://localhost:3306/hive_metrics?user=hive&amp;password=hive</value>
    <description>The default connection string for the database that stores temporary hive statistics.</description>
  </property>

  <property>
    <name>hive.stats.autogather</name>
    <value>true</value>
    <description>A flag to gather statistics automatically during the INSERT OVERWRITE command.</description>
  </property>

  <property>
    <name>hive.stats.default.publisher</name>
    <value></value>
    <description>The Java class (implementing the StatsPublisher interface) that is used by default if hive.stats.dbclass is not JDBC or HBase.</description>
  </property>

  <property>
    <name>hive.stats.default.aggregator</name>
    <value></value>
    <description>The Java class (implementing the StatsAggregator interface) that is used by default if hive.stats.dbclass is not JDBC or HBase.</description>
  </property>

  <property>
    <name>hive.stats.jdbc.timeout</name>
    <value>30</value>
    <description>Timeout value (number of seconds) used by JDBC connection and statements.</description>
  </property>

  <property>
    <name>hive.stats.retries.max</name>
    <value>1</value>
    <description>Maximum number of retries when stats publisher/aggregator got an exception updating intermediate database. Default is no tries on failures.</description>
  </property>

  <property>
    <name>hive.stats.retries.wait</name>
    <value>3000</value>
    <description>The base waiting window (in milliseconds) before the next retry. The actual wait time is calculated by baseWindow * failues + baseWindow * (failure + 1) * (random number between [0.0,1.0]).</description>
  </property>

  <property>
    <name>hive.stats.reliable</name>
    <value>false</value>
    <description>Whether queries will fail because stats cannot be collected completely accurately. 
      If this is set to true, reading/writing from/into a partition may fail becuase the stats 
      could not be computed accurately.
    </description>
  </property>

  <property>
    <name>hive.stats.collect.tablekeys</name>
    <value>true</value>
    <description>Whether join and group by keys on tables are derived and maintained in the QueryPlan.
      This is useful to identify how tables are accessed and to determine if they should be bucketed.
    </description>
  </property>

</configuration>